---
layout: post
title: "CUDA and shared memory allocation"
author: mark_kim
modified: 2016-03-14 13:00
date:   2016-03-14 12:00
tags: []
---

CUDA shared memory allocation is driving me insane. Let's say I make a function call like this:

{% highlight c++ %}

  const size_t shmem_size = thrust::reduce(s_idx, s_idx + 9);
	cudaDecodePar<UInt, bsize, 9> << < grid_size, block_size,shmem_size>> >
		(
		raw_pointer_cast(d_sidx.data()),
		raw_pointer_cast(stream.data()),
		raw_pointer_cast(buffer.data()),
		maxbits,
		intprec,
		kmin,
		group_count);
	cudaStreamSynchronize(0);
 {% endhighlight %}
 
 This launch takes 244.541ms.
 
 But, if we change it to this:


{% highlight c++ %}
	cudaDecodePar<UInt, bsize, 9> << < grid_size, block_size,s_idx[0] + s_idx[1] + s_idx[2] + s_idx[3] + s_idx[4] + s_idx[5] + s_>> >
		(
		raw_pointer_cast(d_sidx.data()),
		raw_pointer_cast(stream.data()),
		raw_pointer_cast(buffer.data()),
		maxbits,
		intprec,
		kmin,
		group_count);
{% endhighlight %}

This launch takes 193.619ms.

However, if we launch it like this:

{% highlight c++ %}
	cudaDecodePar<UInt, bsize, 9> << < grid_size, block_size,64 * 4 + 64 * 4 + 64 * 8 + 64 * 4 + 64 + 64 * 4 + 8*64 + 64*8>> >
		(
		raw_pointer_cast(d_sidx.data()),
		raw_pointer_cast(stream.data()),
		raw_pointer_cast(buffer.data()),
		maxbits,
		intprec,
		kmin,
		group_count);
{% endhighlight %}

This launch takes 134.859ms.

This is one of those really frustrating "quirks" of CUDA. Something as seemingly innocuous as passing a variable for the size of the shared memory can double the runtime.


